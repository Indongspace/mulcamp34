{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+oA5HzECmndIi5effQR0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Indongspace/mulcamp34/blob/main/Spark_ML_240415.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yWFW5aieGav5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf246dd-016d-448e-e096-14a6d3f8d2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar -zxf spark-3.5.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkpfbpiwJFjI",
        "outputId": "20d5afb6-18e2-4750-e99d-4b74423aa412"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u402-ga-2ubuntu1~22.04 [30.8 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u402-ga-2ubuntu1~22.04 [8,873 kB]\n",
            "Fetched 39.7 MB in 3s (13.6 MB/s)\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\""
      ],
      "metadata": {
        "id": "7TjSXxcGJJpr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark -q"
      ],
      "metadata": {
        "id": "ag8HYhJrJPDL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "aTP8GactJRWf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "spark_version = pyspark.__version__\n",
        "print(\"Apache Spark 버전 확인: \" + spark_version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBCAf2rAJT3z",
        "outputId": "a724f0b9-e040-4ae2-8bfd-bdbcfbd9e41c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apache Spark 버전 확인: 3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 기본예제 (Regression)"
      ],
      "metadata": {
        "id": "KQ7aT74sJn9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import seaborn as sns\n",
        "\n",
        "spark = SparkSession.builder.appName(\"regression\").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "x8avpnTkJnA_",
        "outputId": "02044220-a7fd-497d-cab6-da32e9e65b99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d74f55b8d00>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://64226c8c73f1:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>regression</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 불러오기"
      ],
      "metadata": {
        "id": "Y9xXC7IJKOtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tips = sns.load_dataset(\"tips\")\n",
        "tips_df = spark.createDataFrame(tips)\n",
        "tips_df.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ-ZmCOIKAcP",
        "outputId": "b33347db-ef41-4500-f157-0ba47aacc6ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+---+------+----+\n",
            "|total_bill| tip|   sex|smoker|day|  time|size|\n",
            "+----------+----+------+------+---+------+----+\n",
            "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
            "+----------+----+------+------+---+------+----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 변환\n",
        "- 머신러닝 수행 위해 반드시 수행해야 하는 과정\n",
        "- VectorAssembler : https://spark.apache.org/docs/3.5.1/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html"
      ],
      "metadata": {
        "id": "ZOQ5gBuYKSWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# features 존재하지 않음 ==> 생성\n",
        "# 타겟변수는 tip\n",
        "feature_columns = ['total_bill','size'] # 수치형\n",
        "\n",
        "assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'features')\n",
        "df = assembler.transform(tips_df)\n",
        "df.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvedehA-KR55",
        "outputId": "968e538f-78a6-4a17-a02a-480ebf4de6c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+---+------+----+-----------+\n",
            "|total_bill| tip|   sex|smoker|day|  time|size|   features|\n",
            "+----------+----+------+------+---+------+----+-----------+\n",
            "|     16.99|1.01|Female|    No|Sun|Dinner|   2|[16.99,2.0]|\n",
            "+----------+----+------+------+---+------+----+-----------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df.select('features','tip')\n",
        "train.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkCedmbsL6ot",
        "outputId": "61a234a3-e2fa-4df8-d202-811dd05ea3bb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----+\n",
            "|   features| tip|\n",
            "+-----------+----+\n",
            "|[16.99,2.0]|1.01|\n",
            "+-----------+----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 분리\n",
        "- 디폴트로 층화추출 하세요\n",
        "  + pyspark 내부에서는 해당 메서드 미존재\n",
        "  + 직접 사용자 정의함수 개발해서 적용 ==> 불편함 ==> 사람들은 안 씀 ==> 공모전이나 캐글에서 PySpark로 코드 짜는 사람이 없음"
      ],
      "metadata": {
        "id": "yzJIjFpVMRG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train.randomSplit([0.8,0.2],seed=42)"
      ],
      "metadata": {
        "id": "mKdJnzEFMYOk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1fFjUxiPaq1",
        "outputId": "be8c79e3-ae17-4371-9c6c-065bbc73d23c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+\n",
            "|  features|tip|\n",
            "+----------+---+\n",
            "|[3.07,1.0]|1.0|\n",
            "+----------+---+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 회귀모형 학습"
      ],
      "metadata": {
        "id": "T4DmiDE5NqIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "lr = LinearRegression(featuresCol='features', labelCol='tip', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "lr_model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "6HxVaaEtNpV5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model.coefficients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kup77u9_Pwt6",
        "outputId": "072a4928-ee7c-426c-a29a-d3a4c882f67d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([0.0702, 0.1024])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model.intercept"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAPmqkyYP0zP",
        "outputId": "e708840d-cc71-41cf-f9cf-db3b20f53941"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3529536822318204"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 예측"
      ],
      "metadata": {
        "id": "hmYqVsEgQEty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lr_model.transform(test_data)\n",
        "predictions.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMjlmwx2QGNJ",
        "outputId": "65e20214-2349-42c6-f7db-958cf64eebc9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------------------+\n",
            "|  features|tip|        prediction|\n",
            "+----------+---+------------------+\n",
            "|[7.25,1.0]|1.0|1.9641720903635371|\n",
            "+----------+---+------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 평가"
      ],
      "metadata": {
        "id": "abvbTQ2YQdMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(labelCol='tip', predictionCol='prediction', metricName='rmse')\n",
        "\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f771MxpsQcls",
        "outputId": "8df73d65-b3b1-469f-defc-6de152b67f21"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0336986607859564"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파이널 프로젝트\n",
        "- Spark\n",
        "- Scikit-Learn, XGBoost, LightGBM, CatBoost\n",
        "- TabNet (논문정리, 블로그용)\n",
        "- XAI, 모형 설명해주는 도구 (딥러닝을 위한 것)"
      ],
      "metadata": {
        "id": "1GwH9kCsRsf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "VhjDELpBWmOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "Krips3ptSbIG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import seaborn as sns\n",
        "\n",
        "spark = SparkSession.builder.appName(\"classification\").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "mVJb7cimXhKn",
        "outputId": "37585d45-2652-4591-ed1f-f8f4be4df8e4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d74f4f7f970>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://64226c8c73f1:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>classification</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tips = sns.load_dataset(\"tips\")\n",
        "df = spark.createDataFrame(tips)\n",
        "df.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3gaIebDXli4",
        "outputId": "3fb40642-d37a-49c5-c2da-148b6bd829e0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+---+------+----+\n",
            "|total_bill| tip|   sex|smoker|day|  time|size|\n",
            "+----------+----+------+------+---+------+----+\n",
            "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
            "+----------+----+------+------+---+------+----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문자 데이터"
      ],
      "metadata": {
        "id": "5RWHei1HX9JN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df)\n",
        "    for column in ['sex','smoker','day','time']\n",
        "]\n",
        "\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "tips_df = pipeline.fit(df).transform(df)\n",
        "\n",
        "tips_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRbUKtknX_CW",
        "outputId": "db96eadc-063d-4865-fa96-b4dd5dba96d1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+\n",
            "|total_bill| tip|   sex|smoker|day|  time|size|sex_index|smoker_index|day_index|time_index|\n",
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+\n",
            "|     16.99|1.01|Female|    No|Sun|Dinner|   2|      1.0|         0.0|      1.0|       0.0|\n",
            "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|      0.0|         0.0|      1.0|       0.0|\n",
            "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|      0.0|         0.0|      1.0|       0.0|\n",
            "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|      0.0|         0.0|      1.0|       0.0|\n",
            "|     24.59|3.61|Female|    No|Sun|Dinner|   4|      1.0|         0.0|      1.0|       0.0|\n",
            "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|      0.0|         0.0|      1.0|       0.0|\n",
            "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|      0.0|         0.0|      1.0|       0.0|\n",
            "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|      0.0|         0.0|      1.0|       0.0|\n",
            "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|      0.0|         0.0|      1.0|       0.0|\n",
            "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|      0.0|         0.0|      1.0|       0.0|\n",
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VectorAssembler 사용\n",
        "- features : 독립변수\n",
        "- target 변수 구분"
      ],
      "metadata": {
        "id": "v6z5kHlIZZE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols = ['total_bill','tip','size','smoker_index','day_index','time_index'],\n",
        "    outputCol = 'features'\n",
        ")\n",
        "\n",
        "train = assembler.transform(tips_df)\n",
        "train.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1w8QGfHZh4J",
        "outputId": "22d80002-6afb-48d9-ae6c-9ced01f1c4e5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+--------------------+\n",
            "|total_bill| tip|   sex|smoker|day|  time|size|sex_index|smoker_index|day_index|time_index|            features|\n",
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+--------------------+\n",
            "|     16.99|1.01|Female|    No|Sun|Dinner|   2|      1.0|         0.0|      1.0|       0.0|[16.99,1.01,2.0,0...|\n",
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+--------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최종 데이터셋"
      ],
      "metadata": {
        "id": "iJKU04vOaToD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = train.select(\"features\",\"sex_index\")\n",
        "final_data.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfY-AG8_aTNE",
        "outputId": "f2e49be1-f627-4d29-d390-322367238f21"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+\n",
            "|            features|sex_index|\n",
            "+--------------------+---------+\n",
            "|[16.99,1.01,2.0,0...|      1.0|\n",
            "+--------------------+---------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 분리"
      ],
      "metadata": {
        "id": "pZKnJYcsa3fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='sex_index')\n",
        "lr_model = lr.fit(train_data)\n",
        "print(\"Coefficients: \\n\" + str(lr_model.coefficients))\n",
        "print(\"Intercept: \" + str(lr_model.intercept))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEURjVzwa1m-",
        "outputId": "342aa9dd-9743-4de9-a1bc-0daf4e111763"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            "[-0.029542135575379266,0.050979340226452716,-0.0055652867997908265,0.19993263323453486,0.08135603506558281,0.6843956307498666]\n",
            "Intercept: -0.5273389488527473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모형평가\n"
      ],
      "metadata": {
        "id": "pMldmCCBbGyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='sex_index')\n",
        "print('Test Area Under ROC', evaluator.evaluate(predictions))\n",
        "\n",
        "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"sex_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = accuracy_evaluator.evaluate(predictions)\n",
        "print(\"Accuracy: %.3f\" % accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNysqUuRbI7J",
        "outputId": "2480e7c4-571a-4422-fa2f-19c59452004a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Area Under ROC 0.65625\n",
            "Accuracy: 0.690\n"
          ]
        }
      ]
    }
  ]
}